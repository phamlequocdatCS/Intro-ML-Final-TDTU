## Task 1
1. Understanding and comparing various Optimizer methods in training machine learning models.
2. Exploring "Continual Learning and Test Production" in machine learning.

## Optimizers
1. Gradient Descent
    
The gradient of a function $f$ is the vector field $\nabla f$ whose value at a point $p$ gives the direction and the rate of fastest increase. If the gradient of the function is non-zero at $p$, the direction of the gradient is the direction in which the function increases most quickly from $p$, and the magnitude of the gradient is the rate of increase in that direction.

The gradient of a function $f(p)$ for $f:\mathbb{R}^n \rightarrow \mathbb{R}$ where $p=(x_ 1,x_ 2, ...,x_n)$ is defined as:

$$
\nabla f(p) = \begin{bmatrix}
\frac{\partial f}{\partial x_1}(p) \\
\vdots \\
\frac{\partial f}{\partial x_n}(p)
\end{bmatrix}
$$

A point where the gradient is the zero vector is known as a stationary point. A stationary point is a point where the function "stops" increasing or decreasing.
- A **local minima** is one where the derivative of the function changes from negative to positive.
- A **local maxima** is one where the derivative of the function changes from positive to negative.

Using the gradient, we can (hopefully) find a way to reach the local minima of an unknown function $F$, given $\nabla F$ (often the case in the real world). This is called **Gradient descent**.

Considering the neighborhood of a point $\bold{a}$, $F$ decreases fastest if one goes from $\bold{a}$ in the direction of the negative gradient of $F$ at $\bold{a}$, $-\nabla F(a)$.

If $\bold{a}_ {n+1} = \bold{a}_ n - \gamma \nabla F(\bold{a})$, then $F(\bold{a}_ n) \ge F(\bold{a}_ {n+1})$ for a small enough learning rate $\gamma \in \mathbb{R}_ +$. The term $\nabla F(\bold{a})$ is subtracted from $\bold{a}$ because we want to move against the gradient and toward the local minima.

The process of gradient descent starts with a guess $x_ 0$ for a local minima of $F$, then improve upon this guess for $x_ 1, x_ 2, ...$ such that $x_ {n+1} = x_ n - \gamma \nabla F(x), n \ge 0$. Hopefully, the sequence $(x_ n)$ converges to the desired local minimum.

In the context of **Multivariate Linear Regression**, given a linear equation 

$$
y = w_ 0 + w_ 1 x_ 1 + w_ 2 x_ 2 + ... + w_ n x_ n
$$
one can use Gradient Descent to find the weights $(w)$ given the input features $x$ and expected output $y$.

The function that we want to find the local minima of for this problem is a **loss function**, that is how far off the predicted output is from the actual output. There are many types of loss functions, one of which is the **Mean Squared Error** (MSE).

The **hypothesis** $\hat{y}$ given a learned set of weights $(w)$ is:

$$\hat{y} = \sum^{N} _ {i=0} (w_ j x _ {ij})$$

The **Mean Square Error** loss function of the expected output $y$ and the hypothesis $\hat{y}$
$$
L(w_ 0, w_ 1, ..., w_ n) = \frac{1}{N}\sum^{N} _ {i=0} (y_ i - \hat{y}_i)^2
$$
where $N$ is the number of samples in the training dataset.

The gradient $\nabla L$ is found by taking the derivative of the loss function

$$
\nabla L = \begin{bmatrix}
-\frac{2}{N} \sum^{N} _ {i=0} (y_ i - \hat{y}_i)            \\
-\frac{2}{N} \sum^{N} _ {i=0} (y_ i - \hat{y}_i)x_ {i1}     \\
\vdots \\
-\frac{2}{N} \sum^{N} _ {i=0} (y_ i - \hat{y}_i)x_ {in}    
\end{bmatrix}
$$

Finally, we update the weights via the formula 
$$w_ j = w_ j - \alpha \frac{\partial L}{\partial w_ j}, j = 0,1,...n$$
where $\alpha$ is the learning rate and $n$ is the number of features.

This process is repeated until the algorithm converges to a minimum, which is indicated by the gradient becoming very small (almost zero). The learning rate $\alpha$ determines how big the steps the algorithm takes towards the minimum are. If $\alpha$ is too large, the algorithm might overshoot the minimum and diverge. If $\alpha$ is too small, the algorithm will need many iterations to converge and might get stuck in a local minimum.

2. Stochastic Gradient Descent (SGD)
3. Mini-Batch Gradient Descent
4. Momentum
5. Adaptive Gradient Algorithms (Adagrad, RMSProp, Adam)
    1. Root Mean Square Propagation (RMSProp)
    2. Adaptive Moment Estimation (Adam)



Sources: 
1. [Wikipedia - Gradient](https://en.wikipedia.org/wiki/Gradient)
2. [Wikipedia - Stationary point](https://en.wikipedia.org/wiki/Stationary_point)
3. [Wikipedia - Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)